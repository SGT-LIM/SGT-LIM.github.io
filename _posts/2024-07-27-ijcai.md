---
layout: post
title: "[IJCAI24 Workshop] Addressing Image Hallucination in Text-to-Image Generation through Factual Image Retrieval"
collection: papers
permalink: /papers/main-image-hallucination/
date: 2024-07-27
authors: "Youngsun Lim, Hyunjung Shim"
conference: "International Joint Conference on Artificial Intelligence (IJCAI) 2024"
paper_link: "https://arxiv.org/pdf/2407.10683v1"
---

This paper, authored by **Youngsun Lim** and Hyunjung Shim, is accepted at the **IJCAI 2024 Workshop** on Trustworthy Interactive Decision-Making with Foundation Models. (**Oral Presentation**)

## Abstract

Text-to-image generation has shown remarkable progress with the emergence of diffusion models. However, these models often generate factually inconsistent images, failing to accurately reflect the factual information and common sense conveyed by the input text prompts. We refer to this issue as Image hallucination. Drawing from studies on hallucinations in language models, we classify this problem into three types and propose a methodology that uses factual images retrieved from external sources to generate realistic images. Depending on the nature of the hallucination, we employ off-the-shelf image editing tools, either InstructPix2Pix or IP-Adapter, to leverage factual information from the retrieved image. This approach enables the generation of images that accurately reflect the facts and common sense.

## Method

### Overview

We introduce a tuning-free method to enhance text-to-image generation models for producing fact-based images by utilizing factual images retrieved from external sources. The approach involves generating an initial image from a text-to-image model, retrieving relevant images using the input prompt as a search query, and selecting a factual image to guide the correction of hallucinations.

### Image Hallucination Types

1. **Factual Inconsistency**: Occurs due to co-occurrence bias in training data, leading to incorrect representations of facts.
2. **Outdated Knowledge Hallucination**: Arises from the model's inability to reflect temporal changes and updated information.
3. **Factual Fabrication**: Produces images with little to no basis in reality.

### Correction Methods

1. **InstructPix2Pix**: Used for hallucinations affecting specific properties. It generates instructions to correct the initial image using differences between the generated and retrieved images.
2. **IP-Adapter**: Employed for wide and complex hallucinations. It integrates text and image prompts to generate factually accurate images.

### Experimental Setup

1. **Initial Image Generation**: Using DALL-E 3.
2. **Image Retrieval**: Utilizing Google's Custom Search JSON API.
3. **Correction Application**: Applying either InstructPix2Pix or IP-Adapter based on the type of hallucination.

## Results

The proposed method effectively eliminates various types of image hallucinations. For example, the Statue of Liberty was accurately depicted in its original copper brown color as of 1890, and Mount Fuji was shown with minimal snow during summer. The approach also corrected outdated knowledge hallucinations, such as accurately depicting Angela Merkel as the Chancellor of Germany in 2015.

## Value of the Paper

This study addresses a critical gap in text-to-image generation by introducing a method to mitigate image hallucinations through the retrieval and application of factual images. The contributions include:

- Defining the problem of image hallucination in text-to-image generation.
- Proposing a novel methodology that utilizes factual images to correct hallucinations.
- Demonstrating the effectiveness of the approach across various types of hallucinations.

By enhancing the factual accuracy of generated images, this research advances the reliability and trustworthiness of text-to-image generation models.

You can access the full paper [here](https://paperswithcode.com/paper/label-augmented-dataset-distillation) or preview it below:

<iframe src="https://arxiv.org/pdf/2407.10683v1" width="640" height="480"></iframe>
